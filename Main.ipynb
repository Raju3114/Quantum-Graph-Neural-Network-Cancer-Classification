{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y7beub0pxee"
      },
      "outputs": [],
      "source": [
        "# ------------------- Install Required Packages -------------------\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install torch-geometric\n",
        "!pip install pandas numpy scikit-learn networkx openpyxl pennylane matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Import Libraries -------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pennylane as qml\n"
      ],
      "metadata": {
        "id": "LA4ALbxGp2Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Load Dataset from Google Drive -------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "labels_file = '/content/drive/MyDrive/TCGA-PANCAN-HiSeq-801x20531/labels.csv'\n",
        "data_file   = '/content/drive/MyDrive/TCGA-PANCAN-HiSeq-801x20531/data.csv'\n",
        "\n",
        "labels_df   = pd.read_csv(labels_file, index_col=0)\n",
        "features_df = pd.read_csv(data_file, index_col=0)\n",
        "\n",
        "print(\"Features shape:\", features_df.shape)\n",
        "print(\"Labels shape:\", labels_df.shape)\n"
      ],
      "metadata": {
        "id": "k1EVARrup2RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Preprocess Data -------------------\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(labels_df.values.ravel())\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(features_df)\n",
        "\n",
        "# PCA for dimensionality reduction\n",
        "n_components = min(200, X_scaled.shape[0])\n",
        "pca = PCA(n_components=n_components)\n",
        "X_reduced = pca.fit_transform(X_scaled)\n",
        "X_tensor = torch.tensor(X_reduced, dtype=torch.float)\n",
        "\n",
        "# Build graph using k-nearest neighbors\n",
        "num_nodes = X_tensor.shape[0]\n",
        "sim = cosine_similarity(X_tensor)\n",
        "edges = []\n",
        "k = 10\n",
        "for i in range(num_nodes):\n",
        "    neighbors = sim[i].argsort()[-(k+1):-1]\n",
        "    for j in neighbors:\n",
        "        edges.append([i,j])\n",
        "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# PyG Data object\n",
        "data = Data(x=X_tensor, edge_index=edge_index, y=y_tensor)\n",
        "print(data)\n",
        "\n",
        "# Train-test split\n",
        "train_idx, test_idx = train_test_split(\n",
        "    np.arange(len(y_tensor)), test_size=0.2, stratify=y_tensor, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "9KxJ1mA0p2ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Quantum Layer -------------------\n",
        "n_qubits = 8\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_circuit(inputs, weights):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(inputs[i], wires=i)\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "weight_shapes = {\"weights\": (3, n_qubits)}\n",
        "qlayer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n"
      ],
      "metadata": {
        "id": "l1l_TjJbp2um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Quantum GNN Model -------------------\n",
        "class QuantumGNN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim, n_qubits, qlayer):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.fc_reduce = torch.nn.Linear(hidden_dim2, n_qubits)\n",
        "        self.q_layer = qlayer\n",
        "        self.conv_out = GCNConv(n_qubits, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.fc_reduce(x)\n",
        "\n",
        "        # Apply quantum layer per node\n",
        "        x_quantum = []\n",
        "        for i in range(x.shape[0]):\n",
        "            x_quantum.append(self.q_layer(x[i]))\n",
        "        x = torch.stack(x_quantum)\n",
        "\n",
        "        x = F.dropout(x, p=0.3, training=self.training)\n",
        "        x = self.conv_out(x, edge_index)\n",
        "        return x\n",
        "\n",
        "input_dim = X_tensor.shape[1]\n",
        "hidden_dim1 = 128\n",
        "hidden_dim2 = 64\n",
        "output_dim = len(np.unique(y))\n",
        "\n",
        "model = QuantumGNN(input_dim, hidden_dim1, hidden_dim2, output_dim, n_qubits, qlayer)\n"
      ],
      "metadata": {
        "id": "uw8BSa5yp26e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Training -------------------\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "epochs = 170\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_start = time.time()\n",
        "    timestamp_start = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[train_idx], y_tensor[train_idx])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_end = time.time()\n",
        "    timestamp_end = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    print(f\"[Start: {timestamp_start} | End: {timestamp_end}] Epoch {epoch+1}/{epochs}, \"\n",
        "          f\"Loss: {loss.item():.4f}, Time: {epoch_end - epoch_start:.2f}s\")\n"
      ],
      "metadata": {
        "id": "SU-K3Czqp3Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------- Evaluation -------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data.x, data.edge_index)\n",
        "    preds = out.argmax(dim=1)\n",
        "\n",
        "    test_acc = accuracy_score(y_tensor[test_idx].numpy(), preds[test_idx].numpy())\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Basic Confusion Matrix (numeric)\n",
        "    cm = confusion_matrix(y_tensor[test_idx].numpy(), preds[test_idx].numpy())\n",
        "    plt.figure(figsize=(6,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(\"Confusion Matrix (Numeric)\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "vO57xhiQp3cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Evaluate model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out = model(data.x, data.edge_index)\n",
        "    preds = out.argmax(dim=1)\n",
        "\n",
        "    test_acc = accuracy_score(y_tensor[test_idx].numpy(), preds[test_idx].numpy())\n",
        "    print(f\"Final Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_tensor[test_idx].numpy(), preds[test_idx].numpy())\n",
        "    plt.figure(figsize=(6,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "381Exn9EqBz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t-SNE Visualization\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Get quantum embeddings (before final output layer)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    x = F.relu(model.conv1(data.x, data.edge_index))\n",
        "    x = F.relu(model.conv2(x, data.edge_index))\n",
        "    x = model.fc_reduce(x)\n",
        "\n",
        "    # Apply quantum layer per node\n",
        "    x_quantum = []\n",
        "    for i in range(x.shape[0]):\n",
        "        x_quantum.append(model.q_layer(x[i]))\n",
        "    quantum_embeddings = torch.stack(x_quantum).numpy()  # shape: [num_nodes, n_qubits]\n",
        "\n",
        "# t-SNE projection to 2D\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "emb_2d = tsne.fit_transform(quantum_embeddings)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "for label in np.unique(y):\n",
        "    idx = np.where(y == label)\n",
        "    plt.scatter(emb_2d[idx,0], emb_2d[idx,1], label=f'Class {label}', alpha=0.7)\n",
        "plt.xlabel('t-SNE Component 1')\n",
        "plt.ylabel('t-SNE Component 2')\n",
        "plt.title('t-SNE Visualization of Quantum GNN Node Embeddings')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V3edMUXjstlH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}